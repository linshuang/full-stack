# 个人经验记录
## 引言
本文档记录了本人实践时的一些经验。

## 采用嵌入获取特征
深度网络的越深层具备更高级的语义，而浅层对应低级的语义——如线。那么如果想要获得高级特征，可以通过训练分类器，然后嵌入到高层，再训练，拿取嵌入层的输出作为特征

## 训练收敛到输出纯色error
描述：
```
在用unet做图像分割时，训练出的模型预测出纯颜色的图，似乎像是模型陷入了局部最优————纯颜色，然后这个颜色接近于黑白像素的比值。
样本：30
batch_size: 2
steps_per_epoch: 50或15
数据增强：True
ReduceLROnPlateau：True
优化算法：Adam 
```
解决：
```
1) 改变优化算法为sgd
2）调大steps per epoch参数=>300
```
解释：
```
猜测：在每轮epoch时重置adam的先前梯度的指数衰减平均值，从而导致adam失去冲量的特性，同时由于样本跟批数目不大，导致adam没多久就变得平平凡凡，最终导致模型陷入局部最优
```

## 样本少导致模型泛化能力有限
描述
```
训练样本数目较少，导致模型泛化能力有限
```
解决：
```
1. 使用fine-tune技术能够显著提升模型的泛化能力。例如可以使用训练于image-net的模型进行fine-tune。可见 dl-transfer-learning-finetune.md
2. 对数据进行机器增强。可见 ../data-augmentation.md
3. 使用人工进行编辑扩大数据集
4. 假如可以从其它站点爬取，可以采用爬虫技术丰富数据集
```

## 利用patch提升多标签分类器性能
描述
```
在多标签分类器时，想借助人工知识进一步提升性能
```
解决：
```
截取部分内容（patch）成为独立样本并进行标注，例如椅类可标注'皮质'、'布质'、'滚轮'等，那么可截取皮质部分为独立样本，这样的行为能够有指向性地让模型认识到大图中的哪些部分对应哪些标签
```
