# k-means
## 引言
K-means算法是很典型的基于距离的聚类算法，采用距离作为相似性的评价指标，即认为两个对象的距离越近，其相似度就越大。该算法认为簇是由距离靠近的对象组成的，因此把得到紧凑且独立的簇作为最终目标。

核心思想：由用户指定k个初始质心（initial centroids)，以作为聚类的类别（cluster），重复迭代直至算法收敛。

## 算法<sup>[1]
在k-means算法中，用质心来表示cluster；且容易证明k-means算法收敛等同于所有质心不再发生变化。基本的k-means算法流程如下：

```
选取k个初始质心（作为初始cluster）；
repeat：
    对每个样本点，计算得到距其最近的质心，将其类别标为该质心所对应的cluster；
    重新计算k个cluser对应的质心；
until 质心不再发生变化
```
对于欧式空间的样本数据，以平方误差和（sum of the squared error, SSE)作为聚类的目标函数，同时也可以衡量不同聚类结果好坏的指标：

$SSE=∑_{i=1}^k∑_{x∈C_i}dist(x,c_i)$
表示样本点$x$到cluster $C_i$ 的质心 $c_i$ 距离平方和；最优的聚类结果应使得SSE达到最小值。

下图中给出了一个通过4次迭代聚类3个cluster的例子：
![avatar](https://images2015.cnblogs.com/blog/399159/201601/399159-20160131182028552-1529699913.png)

## 缺点<sup>[1]
- k-means是局部最优的，容易受到初始质心的影响；
- k值的选取也会直接影响聚类结果，最优聚类的k值应与样本数据本身的结构信息相吻合，而这种结构信息是很难去掌握，因此选取最优k值是非常困难的。

## 参考
[1] [k-means](http://www.cnblogs.com/en-heng/p/5173704.html)<br/>